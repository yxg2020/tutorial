1.大模型成为热门关键词，ChatGPT的成功更是把大模型推上了风口
2.大模型成为发展通用人工智能的重要途径
	2.1.过去是用专用模型:针对特定任务，一个模型解决一个问题
		2.1.1.深度学习理论突破（2006）--大规模语音识别（2011）--ImageNet竞赛
		（2012）--人脸识别（2014）--围棋比赛（2016）--德州扑克（2019）--
		AlphaFold（2021）
	2.2.通用大模型：一个模型应对多种任务，多种模态
		2.2.1ChatGPT（GPT-4）,文心一言，讯飞星火等等
3.书生·浦语大模型开源历程
	3.1.2023年6月7日--InternLM千亿参数大模型发布；
		7月6日--千亿参数大模型全面升，支持8K语境，26种语言；全面开源免费使用； 
		 InternLM-7B模型，全链条开源工具体系；
		 8月14日--书生·万卷1.0多模态预训练语料库开源发布；
		 8月21日--升级版对话，模型InternLM-Chat-7Bv1.1发布，开源智能体系框架
		 Lagent,支持从语言模型到智能体系升级转换；
		 8月28日--InternLM千亿参数模型，参数量升级至123B；
		 9月20日--增强版InternLM-20B开源，开源工具链全线升级；
4.书生·浦语大模型系列
		4.1.轻量级：InternLM-7B--社区低成本可用最佳模型规模
	4.2.中量级：InternLM-20B--商业场景可开发定制高精度较小模型规模
	4.3.重量级：InternLM-123B--通用大语言模型能力全面覆盖千亿规模
5.书生·浦语20B开源大模型性能
	5.1全面领先相近量级的开源模型；
	5.2以不足三分之一的参数量，达到Llama-70B水平。
6.从模型到应用
	6.1智能客服；个人助手；行业应用。
	6.2模型选型（评测）--业务场景是否复杂-
		-是--算力足够嘛-
			-是--续训/全参数微调--是否需要环境交互-
				-是--构建智能体-------------------模型评测--模型部署
				-否------------------------------模型评测--模型部署
			-否--部分参数微调-----是否需要环境交互-
				-是--构建只能提-------------------模型评测--模型部署
				-否------------------------------模型评测--模型部署
		-否----------------------------------------模型评测--模型部署		
7.书生·浦语大模型全链路开源体系
	7.1.数据--书生·万卷--2TB数据，涵盖多种模态与任务
	7.2.预训练--InternLM-Train--并行训练，极致优化，速度达到
	3600 tokens/sec/gpu
	7.3.微调--XTuner--支持全参微调，支持LoRA等低成本微调
	7.4.部署--LMdeploy--全链路部署，性能领先，每秒生成2000+tokens
	7.5.评测--OpenCompass--全方位评测，性能可复现，80万套评测集，40万道题目
	7.6.应用--Lagent AgentLego--支持多种智能体，支持代码解释器等多种工具
8.全链路开源体系|数据
	8.1.书生·万卷1.0
		8.1.1文本数据：50亿个文档；数据量超1TB
		8.1.2图像-文本数据集：超2200万个文件；数据量超140GB
		8.1.3视频数据：超1000个文件；数据量超900GB
		8.1.4多模态融合-涵盖领域广；
		8.1.5精细化处理--数据清洗；
		8.1.6价值观对齐--合规处理。
	8.2.openDatalab--丰富多样的开发数据
9.全链路开源体系|预训练
	9.1.高可扩展--支持8卡到千卡训练，千卡加速效率达92%
	9.2.极致性能优化--Hybrid Zero 独特技术+极致优化，加速50%
	9.3.兼容主流--无缝接入HuggingFace等技术生态，支持各类轻量化技术
	9.4开箱即用--支持多种规格语言模型，修改配置即可训练
10.全链路开源体系|微调
	10.1.增量续训
	--使用场景：让基座模型学习到一些新知识，如某个垂直领域知识
	--训练数据：文章，书籍，代码等
	10.2.有监督微调
	--使用场景:让模型学会理解和遵循各种指令，或者注入少量领域知识
	--训练数据：高质量的对话，问答数据	
	10.3.高效微调框架XTuner
	--适配多种生态：多种微调算法；适配多种开源生态；自动优化加速；
	--适配多种配件：训练方案覆盖NVIDIA 20系以上所有显卡；最低只需8GB显存即可微
	调7B模型
11.全链路开源体系|评测
	11.1.国内外评测体系的整体态势
	--机构：OpenLLM Leaderboard,Stanford,Hugging Face
	--类型：客观/主观评测
	--量级：英文题目，中文题目，中英双语
	11.2.OpenCompass--全球领先的大模型开源评测体系（6大维度，80+评测集，40万
	+评测题目）
	--学科：初中-中国高考--大学考试；语言能力考试；职业资格考试
	--语言：字词释义，成语习语，语义相似，指代消解，翻译
	--知识：知识问答，多语种知识问答
	--理解：阅读理解，内容分析，内容总结
	--推理：因果推理,常识推理，代码推理，数学推理
	--安全：偏见，有害性，公平性，隐私性，真实性，合法性
	11.3.OpenCompass开源评测平台架构
	--工具层：分布式评测，提示词工程，评测数据库上报，评测榜单发布，评测报告生成
	--方法层：自动化客观评测，基于模型辅助的主观评测，基于人类反馈的主观评测
	--能力层：通用能力-学科，语言，知识，理解，推理，安全；特色能力-长文本，代
	码，工具，知识增强
	--模型层：基座模型，对话模型
	--特点：丰富模型支持-开源模型，API模型一站式评测；分布式高效评测-支持千亿参
	数模型在海量数据集上分布式评测；便捷的数据集接口-支持社区用户根据自身需求快
	速添加自定义数据集；敏捷的能力迭代-每周更新大模型能力版单，每月提升评测工具
	能力。
12.全链路开源体系|部署
	12.1.大模型语言特点
	--内存开销巨大：庞大的参数量；采用自回归生成token，需要缓存k/v
	--动态Shape:请求数不固定；token逐个生成，且数量不定
	--模型结构相对简单：transformer结构，大部分是decoder-only
	12.2.技术挑战
	--设备：低存储设备（消费级显卡，移动端等）如何部署？
	--推理：如何加速token的生成速度；如何解决动态shape，让推理可以不间断；如何
	有效管理和利用内存
	--服务：提升系统整体吞吐量；降低请求的平均响应时间
	12.3.部署方案
	--技术点：模型并行；低比特量化；Attention优化；计算和访存优化；Continuous
	 Batching
	 12.4.LMDeploy提供大模型在GPU上部署的全流程解决方案，包括模型轻量化，推理和
	 服务
	 --高效推理引擎：持续批处理技巧；深度优化的低比特计算Kernel;模型并行；高效
	 的K/V缓存管理机制
	 --完备易用的工具链：量化，推理，服务全流程；无缝对接OpenCompass评测推理精
	 度；和OpenAI接口高度兼容API server
	 --领先的推理性能
	 --静态推理性能：固定batch,输入/输出token数量
13.全链路开源体系|应用--智能体
	13.1.大语言模型的局限性
	--最新消息和知识的获取
	--回复的可靠性
	--数学计算
	--工具使用和交互
	13.2.轻量级智能体框架Lagent
	--支持多种类型的智能体能力
	--灵活支持多种大语言模型
	--简单拓展，支持丰富的工具
	--例：代码解数学题；零样本泛化：多模态AI工具
	13.3.多模态智能体工具箱AgentLego
	--丰富的工具集合
	--支持多个主流智能体系统
	--灵活的多模态工具调用接口
	--一键式远程工具部署
